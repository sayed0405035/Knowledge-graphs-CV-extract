{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc504f62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-06T10:35:24.066699Z",
     "iopub.status.busy": "2022-09-06T10:35:24.065657Z",
     "iopub.status.idle": "2022-09-06T10:35:24.093440Z",
     "shell.execute_reply": "2022-09-06T10:35:24.092070Z"
    },
    "papermill": {
     "duration": 0.042116,
     "end_time": "2022-09-06T10:35:24.097683",
     "exception": false,
     "start_time": "2022-09-06T10:35:24.055567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cvalltogether/CV_brief.pdf\n",
      "/kaggle/input/cvalltogether/drmperfect_cv-april-2020.pdf\n",
      "/kaggle/input/cvalltogether/vita_external.pdf\n",
      "/kaggle/input/cvalltogether/Klar CV.pdf\n",
      "/kaggle/input/cvalltogether/blee_cv_2016.pdf\n",
      "/kaggle/input/cvalltogether/Canales_Robert_CV.pdf\n",
      "/kaggle/input/cvalltogether/MOORE-MONROY2015_0.pdf\n",
      "/kaggle/input/cvalltogether/CURRICULUM-VITAE_DHG_012519.pdf\n",
      "/kaggle/input/cvalltogether/RobertsonCV0818-2.pdf\n",
      "/kaggle/input/cvalltogether/hameroff2016cv_0.pdf\n",
      "/kaggle/input/cvalltogether/Alison-M-Meadow-cv.pdf\n",
      "/kaggle/input/cvalltogether/agaspar_cv.pdf\n",
      "/kaggle/input/cvalltogether/JO - 2171.pdf\n",
      "/kaggle/input/cvalltogether/Hoit CV (4-11-16).pdf\n",
      "/kaggle/input/cvalltogether/Liverman Selected CV May 2018.pdf\n",
      "/kaggle/input/cvalltogether/LBarraza CV 2020.pdf\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "277cdb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:35:24.119873Z",
     "iopub.status.busy": "2022-09-06T10:35:24.118672Z",
     "iopub.status.idle": "2022-09-06T10:35:49.789356Z",
     "shell.execute_reply": "2022-09-06T10:35:49.787817Z"
    },
    "papermill": {
     "duration": 25.684761,
     "end_time": "2022-09-06T10:35:49.792661",
     "exception": false,
     "start_time": "2022-09-06T10:35:24.107900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\r\n",
      "  Downloading PyPDF2-2.10.5-py3-none-any.whl (216 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.9/216.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from PyPDF2) (4.1.1)\r\n",
      "Installing collected packages: PyPDF2\r\n",
      "Successfully installed PyPDF2-2.10.5\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting pdfplumber\r\n",
      "  Downloading pdfplumber-0.7.4-py3-none-any.whl (40 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting pdfminer.six==20220524\r\n",
      "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.7/site-packages (from pdfplumber) (9.1.1)\r\n",
      "Requirement already satisfied: Wand>=0.6.7 in /opt/conda/lib/python3.7/site-packages (from pdfplumber) (0.6.8)\r\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from pdfminer.six==20220524->pdfplumber) (2.1.0)\r\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.7/site-packages (from pdfminer.six==20220524->pdfplumber) (37.0.2)\r\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=36.0.0->pdfminer.six==20220524->pdfplumber) (1.15.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20220524->pdfplumber) (2.21)\r\n",
      "Installing collected packages: pdfminer.six, pdfplumber\r\n",
      "Successfully installed pdfminer.six-20220524 pdfplumber-0.7.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mcomplete\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install pdfplumber\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6754a395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:35:49.810815Z",
     "iopub.status.busy": "2022-09-06T10:35:49.810413Z",
     "iopub.status.idle": "2022-09-06T10:36:03.692209Z",
     "shell.execute_reply": "2022-09-06T10:36:03.690513Z"
    },
    "papermill": {
     "duration": 13.894226,
     "end_time": "2022-09-06T10:36:03.695009",
     "exception": false,
     "start_time": "2022-09-06T10:35:49.800783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#all import\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#to store data\n",
    "allCVData=[]\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85ec6a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.714021Z",
     "iopub.status.busy": "2022-09-06T10:36:03.712340Z",
     "iopub.status.idle": "2022-09-06T10:36:03.723641Z",
     "shell.execute_reply": "2022-09-06T10:36:03.722029Z"
    },
    "papermill": {
     "duration": 0.022949,
     "end_time": "2022-09-06T10:36:03.726089",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.703140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# to do : do partial match , i.e. word+etc\n",
    "\n",
    "reference=[ \n",
    "            #node1\n",
    "            \"articles\",\"article\",\"books\",\"book\",\"chapters\",\"chapter\",\"citations\",\"citation\",\"editorials\",\"editorial\",\"journals\",\"journal\",\n",
    "               \"seminars\",\"seminar\",\"scholarly\",\n",
    "            #node2\n",
    "            \"awards\",\"award\",\"proposals\",\"proposal\",\"grants\",\"grant\",\"honors\",\"honor\",\"scholarships\",\"scholarship\",\"sponsored\",\n",
    "            #node3\n",
    "            \"appointments\",\"appointment\",\"experiences\",\"experience\",\"services\",\"service\",\"employments\",\"employment\",\"practices\",\"practice\",\n",
    "                \"professionals\",\"professional\",\n",
    "            #node4\n",
    "            \"affiliations\",\"affiliation\",\"memberships\",\"membership\",\"committees\",\"committee\",\n",
    "            #node5\n",
    "            \"contacts\",\"contact\",\"introductions\",\"introduction\",\n",
    "            #node6\n",
    "            \"publications\",\"publication\",\"conferences\",\"conference\",\"presentations\",\"presentation\",\"newsletters\",\"newsletter\",\"reports\",\"report\",\n",
    "            #node7\n",
    "            \"educations\",\"education\",\"certificates\",\"certificate\",\"certifications\",\"certification\",\n",
    "            #node8\n",
    "            \"researches\",\"research\",\n",
    "            #node9\n",
    "            \"teaching\",\"outreaches\",\"outreach\"\n",
    "          ]\n",
    "\n",
    "#allCVData.append((\"fileName\",\"personName\",\"sectionName\",\"head\",\"relation/lebel\",\"tail\"))\n",
    "\n",
    "#print(allCVData)\n",
    "#print(reference,len(reference))\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564ef091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.744681Z",
     "iopub.status.busy": "2022-09-06T10:36:03.743753Z",
     "iopub.status.idle": "2022-09-06T10:36:03.755794Z",
     "shell.execute_reply": "2022-09-06T10:36:03.754236Z"
    },
    "papermill": {
     "duration": 0.025395,
     "end_time": "2022-09-06T10:36:03.759734",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.734339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def dfPartByPart(textList):\n",
    "    collectedText=[]\n",
    "    collectedByDictionary=dict()\n",
    "    collectedParts=dict()\n",
    "    keyDictionary=\"introductions\"\n",
    "    temp=[]\n",
    "\n",
    "    \n",
    "\n",
    "    for smallPartText in textList:\n",
    "        if smallPartText==None:\n",
    "            continue\n",
    "   \n",
    "        for partOfSmallPartText in smallPartText.split():\n",
    "            if len(partOfSmallPartText)<2:\n",
    "                continue\n",
    "            result = list(filter(lambda x: x==partOfSmallPartText.lower(), reference))\n",
    "            \n",
    "            if result:\n",
    "                #print(result,keyDictionary,temp,smallPartText)\n",
    "                #print(result,smallPartText)\n",
    "                collectedText.append(temp)\n",
    "                if keyDictionary in collectedByDictionary:\n",
    "                    collectedByDictionary[keyDictionary]=collectedByDictionary[keyDictionary]+temp\n",
    "                else:\n",
    "                    collectedByDictionary[keyDictionary]=temp\n",
    "                keyDictionary=result[0]\n",
    "                #print(result,keyDictionary)\n",
    "                temp=[]\n",
    "                break\n",
    "        \n",
    "        temp.append(smallPartText)\n",
    "    \n",
    "    \n",
    "    collectedText.append(temp)\n",
    "    if keyDictionary in collectedByDictionary:\n",
    "        collectedByDictionary[keyDictionary]=collectedByDictionary[keyDictionary]+temp\n",
    "    else:\n",
    "        collectedByDictionary[keyDictionary]=temp\n",
    "\n",
    "    return collectedByDictionary\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451d3696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.779097Z",
     "iopub.status.busy": "2022-09-06T10:36:03.778338Z",
     "iopub.status.idle": "2022-09-06T10:36:03.799134Z",
     "shell.execute_reply": "2022-09-06T10:36:03.797532Z"
    },
    "papermill": {
     "duration": 0.033345,
     "end_time": "2022-09-06T10:36:03.801607",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.768262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def reDistribute(prevSectionDictionary):\n",
    "    revisedSectionDictionary=dict()\n",
    "\n",
    "    for sectionPart in prevSectionDictionary:\n",
    "        if sectionPart in [\"articles\",\"article\",\"books\",\"book\",\"chapters\",\"chapter\",\"citations\",\"citation\",\"editorials\",\"editorial\",\"journals\",\"journal\",\"seminars\",\"seminar\",\"scholarly\"]:\n",
    "        \n",
    "            temp=\"articles / books / chapters / citations / editorials / journals / seminars / scholarly\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"awards\",\"award\",\"proposals\",\"proposal\",\"grants\",\"grant\",\"honors\",\"honor\",\"scholarships\",\"scholarship\",\"sponsored\"]:\n",
    "        \n",
    "            temp=\"awards / grants / proposals / honors / scholarships / sponsored\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "    \n",
    "        elif sectionPart in [\"appointments\",\"appointment\",\"experiences\",\"experience\",\"services\",\"service\",\"employments\",\"employment\",\"practices\",\"practice\",\"professionals\",\"professional\"]:\n",
    "        \n",
    "            temp=\"appointments / experiences / services / employments / practices / professionals\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"affiliations\",\"affiliation\",\"memberships\",\"membership\",\"committees\",\"committee\"]:\n",
    "        \n",
    "            temp=\"affiliations / memberships / committees\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"contacts\",\"contact\",\"introductions\",\"introduction\"]:\n",
    "        \n",
    "            temp=\"contacts / introductions\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"publications\",\"publication\",\"conferences\",\"conference\",\"presentations\",\"presentation\",\"newsletters\",\"newsletter\",\"reports\",\"report\"]:\n",
    "        \n",
    "            temp=\"publications / conferences / presentations / newsletters / reports\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"educations\",\"education\",\"certificates\",\"certificate\",\"certifications\",\"certification\"]:\n",
    "        \n",
    "            temp=\"educations / certificates / certifications\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"researches\",\"research\"]:\n",
    "        \n",
    "            temp=\"researches\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "        elif sectionPart in [\"teaching\",\"outreaches\",\"outreach\"]:\n",
    "        \n",
    "            temp=\"teaching / outreaches\"\n",
    "            if temp in revisedSectionDictionary:\n",
    "            \n",
    "                revisedSectionDictionary[temp].extend(prevSectionDictionary[sectionPart])\n",
    "            else:\n",
    "                revisedSectionDictionary[temp]=prevSectionDictionary[sectionPart]\n",
    "    return revisedSectionDictionary\n",
    "    \n",
    "    \n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e205e3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.819934Z",
     "iopub.status.busy": "2022-09-06T10:36:03.819202Z",
     "iopub.status.idle": "2022-09-06T10:36:03.838093Z",
     "shell.execute_reply": "2022-09-06T10:36:03.835784Z"
    },
    "papermill": {
     "duration": 0.031452,
     "end_time": "2022-09-06T10:36:03.841058",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.809606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "#from nltk.corpus import stopwords\n",
    "# load pre-trained model\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "# Education Degrees\n",
    "EDUCATIONDEGREE = [\n",
    "            'BE','B.E.', 'B.E', 'BS', 'B.S','B.S.','BSC','B.SC','B.SC.','C.A.','B.COM','BCOM',\n",
    "            'M.COM', 'MCOM','M.COM.',\n",
    "            'ME', 'M.E', 'M.E.', 'MS', 'M.S','M.S.','MSC','M.SC','M.SC.',\n",
    "            'BTECH', 'B.TECH','B.TECH.', 'M.TECH','M.TECH.', 'MTECH',\n",
    "            'PHD','PH.D', 'PH.D.','MBA','GRADUATE', \n",
    "            'POST-GRADUATE','MASTERS',\n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE', 'X', 'XII'\n",
    "        ]\n",
    "def extract_educationDegree(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    # Sentence Tokenizer\n",
    "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
    "    edu = []\n",
    "    \n",
    "    # Extract education degree\n",
    "    for index, text in enumerate(nlp_text):\n",
    "        text=text.replace(\",\",\" \")\n",
    "        #print(text)\n",
    "        for tex in text.split():\n",
    "            # Replace all special symbols\n",
    "            #tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            \n",
    "            if tex.upper() in EDUCATIONDEGREE and tex not in STOPWORDS:\n",
    "                \n",
    "                if tex not in edu:\n",
    "                    edu.append(tex)\n",
    "                                \n",
    "                \n",
    "    return edu\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3849013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.860250Z",
     "iopub.status.busy": "2022-09-06T10:36:03.859844Z",
     "iopub.status.idle": "2022-09-06T10:36:03.872051Z",
     "shell.execute_reply": "2022-09-06T10:36:03.870389Z"
    },
    "papermill": {
     "duration": 0.024794,
     "end_time": "2022-09-06T10:36:03.874650",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.849856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# Grad all general stop words\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "# Education Degrees\n",
    "Dsignation = [\n",
    "    'assistant professor','associate professor','assistant','affiliate','adjunct faculty',\n",
    "    'associate research professor','associate research scientist','assistant specialist',\n",
    "    'adjunct assistant research scientist',\n",
    "    'instructor',\n",
    "    'manager',\n",
    "    'postdoctoral researcher','program manager','project manager','professor',\n",
    "    'program evaluator','post-doctoral fellow','postdoctoral research fellowship',\n",
    "    'research assistant','research technician',\n",
    "    'senior research associate','staff scientist','seasonal position','specialist',\n",
    "    'teaching assistant','teachers assistant'\n",
    "        ]\n",
    "def extractDsignation(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    # Sentence Tokenizer\n",
    "    nlp_text = [sent.text.strip() for sent in nlp_text.sents]\n",
    "    edu = []\n",
    "    \n",
    "    # Extract education degree\n",
    "    for index, text in enumerate(nlp_text):\n",
    "        text=text.replace(\",\",\" \")\n",
    "        if text.lower() in Dsignation and tex not in STOPWORDS:\n",
    "                \n",
    "            if text not in edu:\n",
    "                edu.append(text)\n",
    "        #print(text)\n",
    "        for tex in text.split():\n",
    "            # Replace all special symbols\n",
    "            #tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            \n",
    "            if tex.lower() in Dsignation and tex not in STOPWORDS:\n",
    "                \n",
    "                if tex not in edu:\n",
    "                    edu.append(tex)\n",
    "                                \n",
    "                \n",
    "    return edu\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b1de8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.894632Z",
     "iopub.status.busy": "2022-09-06T10:36:03.893743Z",
     "iopub.status.idle": "2022-09-06T10:36:03.900513Z",
     "shell.execute_reply": "2022-09-06T10:36:03.899295Z"
    },
    "papermill": {
     "duration": 0.020778,
     "end_time": "2022-09-06T10:36:03.904233",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.883455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#import re\n",
    "#from datetime import datetime\n",
    "def getDate(dataMaybeDate):\n",
    "    \n",
    "\n",
    "    match = re.match(r'.*([1-3][0-9]{3})', dataMaybeDate)\n",
    "    if match is not None:\n",
    "        # Then it found a match!\n",
    "        #print(match.group(1))\n",
    "        print(match)\n",
    "        return match.group()\n",
    "    return None\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7703535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.923845Z",
     "iopub.status.busy": "2022-09-06T10:36:03.922755Z",
     "iopub.status.idle": "2022-09-06T10:36:03.931664Z",
     "shell.execute_reply": "2022-09-06T10:36:03.930175Z"
    },
    "papermill": {
     "duration": 0.02085,
     "end_time": "2022-09-06T10:36:03.933977",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.913127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def newGetDate(dataMaybeDate):\n",
    "    match = re.search('\\d{4}',dataMaybeDate)\n",
    "    match001=re.search('\\d{2}/\\d{2}/\\d{4}',dataMaybeDate)\n",
    "    \n",
    "    #if match001 is not None and int(match001)>1900 and int(match001)<2023:\n",
    "    if match001:\n",
    "        # Then it found a match!\n",
    "        #print(type(match001))\n",
    "        return match001.group(0)\n",
    "    \n",
    "    if match is not None :\n",
    "        # Then it found a match!\n",
    "        if int(match.group(0))>1900 and int(match.group(0))<2023:\n",
    "            return match.group(0)\n",
    "        return None\n",
    "    return None\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba968293",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.953101Z",
     "iopub.status.busy": "2022-09-06T10:36:03.952286Z",
     "iopub.status.idle": "2022-09-06T10:36:03.960689Z",
     "shell.execute_reply": "2022-09-06T10:36:03.959301Z"
    },
    "papermill": {
     "duration": 0.020684,
     "end_time": "2022-09-06T10:36:03.963042",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.942358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def findInstitute(tika_text):\n",
    "    sub_patterns = ['[A-Z][a-z]* University',\n",
    "                    '[A-Z][a-z]* Educational Institute',\n",
    "                '[A-Z][a-z]* College',\n",
    "                'University of [A-Z][a-z]*',\n",
    "                'The University of [A-Z][a-z]*',\n",
    "                    'TheUniversityof[A-Z][a-z]*',\n",
    "                'Ecole [A-Z][a-z]*',\n",
    "                   '[A-Z][a-z]*University',\n",
    "                    '[A-Z][a-z]*EducationalInstitute',\n",
    "                '[A-Z][a-z]*College',\n",
    "                'Universityof[A-Z][a-z]*',\n",
    "                'Ecole[A-Z][a-z]*',\n",
    "                    'The [A-Z][a-z]* Academy of [A-Z][a-z]*',\n",
    "                    'the [A-Z][a-z]* academy of [A-Z][a-z]*'\n",
    "                   ]\n",
    "    pattern = '({})'.format('|'.join(sub_patterns))\n",
    "    matches = re.findall(pattern, tika_text)\n",
    "\n",
    "    return matches\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28b7130b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:03.982301Z",
     "iopub.status.busy": "2022-09-06T10:36:03.981456Z",
     "iopub.status.idle": "2022-09-06T10:36:03.989410Z",
     "shell.execute_reply": "2022-09-06T10:36:03.987627Z"
    },
    "papermill": {
     "duration": 0.021101,
     "end_time": "2022-09-06T10:36:03.992612",
     "exception": false,
     "start_time": "2022-09-06T10:36:03.971511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def removePrefix(dataSent):\n",
    "    resDataIndex=0\n",
    "    for i in dataSent:\n",
    "        #if i.isalpha():\n",
    "        if i.isalnum():\n",
    "            #print(i,resDataIndex)\n",
    "            break\n",
    "        resDataIndex+=1\n",
    "    dataSent=dataSent[resDataIndex:]\n",
    "    return dataSent\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dcaab26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:04.013136Z",
     "iopub.status.busy": "2022-09-06T10:36:04.012694Z",
     "iopub.status.idle": "2022-09-06T10:36:04.923582Z",
     "shell.execute_reply": "2022-09-06T10:36:04.921961Z"
    },
    "papermill": {
     "duration": 0.924751,
     "end_time": "2022-09-06T10:36:04.926312",
     "exception": false,
     "start_time": "2022-09-06T10:36:04.001561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# initialize matcher with a vocab\n",
    "matcher = Matcher(nlp.vocab)\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    \n",
    "    # First name and Last name are always Proper Nouns\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "    matcher.add('NAME', [pattern], on_match = None)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    res=[]\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        temp=span.text\n",
    "        if len(temp)>0:\n",
    "            lastoption=temp\n",
    "        if (\"vitae\" in temp.lower() or \"sciences\" in temp.lower() \n",
    "            or \"engineering\" in temp.lower() or \"biographical\" in temp.lower() \n",
    "            or \"no\" in temp.lower() or \"title\" in temp.lower() ):\n",
    "            continue\n",
    "        res.append(temp)\n",
    "    \n",
    "    return res\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7998c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:04.946328Z",
     "iopub.status.busy": "2022-09-06T10:36:04.945119Z",
     "iopub.status.idle": "2022-09-06T10:36:04.952549Z",
     "shell.execute_reply": "2022-09-06T10:36:04.951158Z"
    },
    "papermill": {
     "duration": 0.020411,
     "end_time": "2022-09-06T10:36:04.955433",
     "exception": false,
     "start_time": "2022-09-06T10:36:04.935022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#E-MAIL\n",
    "#import re\n",
    "def get_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return r.findall(string)\n",
    "\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1766d06a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:04.976745Z",
     "iopub.status.busy": "2022-09-06T10:36:04.975943Z",
     "iopub.status.idle": "2022-09-06T10:36:04.991351Z",
     "shell.execute_reply": "2022-09-06T10:36:04.989517Z"
    },
    "papermill": {
     "duration": 0.029563,
     "end_time": "2022-09-06T10:36:04.994097",
     "exception": false,
     "start_time": "2022-09-06T10:36:04.964534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def handleEducations(listOfEducations):\n",
    "    eduData=[]\n",
    "    pieceEduData=dict()\n",
    "    rest=\"\"\n",
    "    for eduPart in listOfEducations:\n",
    "        #print(type(eduPart))\n",
    "        \n",
    "        res=extract_educationDegree(eduPart)\n",
    "        if res:\n",
    "            if len(pieceEduData)!=0:\n",
    "                if len(rest)>1:\n",
    "                    pieceEduData[\"total details\"]=rest\n",
    "                    rest=\"\"\n",
    "                eduData.append(pieceEduData)\n",
    "                pieceEduData=dict()\n",
    "            pieceEduData[\"degree\"]=res[0]\n",
    "            index001=eduPart.find(res[0])\n",
    "            eduPart=eduPart[:index001]+eduPart[index001+len(res[0]):]\n",
    "            #print(res,index001,eduPart)\n",
    "            #print(res,eduPart)\n",
    "        #datePart=getDate(eduPart)\n",
    "        newDatePart=newGetDate(eduPart)\n",
    "        \n",
    "        #if datePart:\n",
    "        #    print(\"date:\",datePart)\n",
    "        if newDatePart:\n",
    "            pieceEduData[\"date\"]=newDatePart\n",
    "            index002=eduPart.find(newDatePart)\n",
    "            eduPart=eduPart[:index002]+eduPart[index002+len(newDatePart):]\n",
    "            #print(index002,\"date:\",newDatePart,eduPart)\n",
    "        \n",
    "        #test001=eduPart.split(\":\")\n",
    "        #for itest in test001:\n",
    "        if \"advisor\" in eduPart.lower():\n",
    "            \n",
    "            index003=eduPart.lower().find(\"advisor\")\n",
    "            advis001=eduPart[index003+len(\"advisor\"):]\n",
    "            advis001=removePrefix(advis001)\n",
    "            pieceEduData[\"advisor\"]=advis001\n",
    "            eduPart=eduPart[:index003]\n",
    "            #print(\"advisor\",advis001,eduPart)\n",
    "        org=findInstitute(eduPart)\n",
    "        if org:\n",
    "            pieceEduData[\"organization\"]=org[0]\n",
    "            index004=eduPart.find(org[0])\n",
    "            eduPart=eduPart[:index004]+eduPart[index004+len(org[0]):]\n",
    "            #print(org,eduPart)\n",
    "        #print(eduPart)\n",
    "        eduPart=removePrefix(eduPart)\n",
    "        \n",
    "        designation=extractDsignation(eduPart)\n",
    "        if designation:\n",
    "            pieceEduData[\"designation\"]=designation[0]\n",
    "            index004=eduPart.find(designation[0])\n",
    "            eduPart=eduPart[:index004]+eduPart[index004+len(designation[0]):]\n",
    "        \n",
    "        if len(eduPart)>1:\n",
    "            rest+=eduPart\n",
    "        #print(eduPart)\n",
    "        \n",
    "        \n",
    "    if len(pieceEduData)!=0:\n",
    "        if len(rest)>1:\n",
    "            pieceEduData[\"total details\"]=rest\n",
    "                    #rest=\"\"\n",
    "        eduData.append(pieceEduData)\n",
    "    return eduData\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d84ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:05.013782Z",
     "iopub.status.busy": "2022-09-06T10:36:05.013358Z",
     "iopub.status.idle": "2022-09-06T10:36:05.024094Z",
     "shell.execute_reply": "2022-09-06T10:36:05.022714Z"
    },
    "papermill": {
     "duration": 0.02328,
     "end_time": "2022-09-06T10:36:05.026406",
     "exception": false,
     "start_time": "2022-09-06T10:36:05.003126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def handleContacts(sentDataContacts):\n",
    "    \n",
    "    contactDetails=dict()\n",
    "    \n",
    "    #otherDetails=[]\n",
    "    \n",
    "    #print(sentDataContacts)\n",
    "    textContacts001=\",\".join(sentDataContacts)\n",
    "    nameContacts001=extract_name(textContacts001)\n",
    "    if nameContacts001:\n",
    "        contactDetails[\"name\"]=nameContacts001[0]\n",
    "    else:\n",
    "        contactDetails[\"name\"]=sentDataContacts[0]\n",
    "    \n",
    "    #flagContact=False\n",
    "    othersRests=[]\n",
    "    #print(nameContacts001[0],nameContacts001)\n",
    "    for contacts00 in sentDataContacts:\n",
    "        #dateFound001=newGetDate(contacts00)\n",
    "        #print(dateFound001,contacts00)\n",
    "        \n",
    "        \n",
    "        \n",
    "        e_mailContacts=get_email_addresses(contacts00)\n",
    "        if e_mailContacts:\n",
    "            #print(e_mailContacts,contacts00)\n",
    "            #contactIndex001=contacts00.lower().find(e_mailContacts)\n",
    "            contactIndex001=contacts00.find(e_mailContacts[0])\n",
    "            \n",
    "            contacts00=contacts00[:contactIndex001]+contacts00[contactIndex001+len(e_mailContacts[0]):]\n",
    "            contacts00=removePrefix(contacts00)\n",
    "            \n",
    "            \n",
    "            contactDetails[\"e-mails\"]=e_mailContacts[0]\n",
    "            #print(e_mailContacts,contacts00)\n",
    "        othersRests.append(contacts00)\n",
    "    contactDetails[\"other_details\"]=\" \".join(othersRests)\n",
    "    return contactDetails\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fdef3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:05.047054Z",
     "iopub.status.busy": "2022-09-06T10:36:05.046138Z",
     "iopub.status.idle": "2022-09-06T10:36:05.063245Z",
     "shell.execute_reply": "2022-09-06T10:36:05.061463Z"
    },
    "papermill": {
     "duration": 0.030991,
     "end_time": "2022-09-06T10:36:05.066489",
     "exception": false,
     "start_time": "2022-09-06T10:36:05.035498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def handlePublications(textPublications):\n",
    "    allPublications=[]\n",
    "    detailsPublications=\"\"\n",
    "    tempPublications=dict()\n",
    "    flag=False # need for different in the 1st publication\n",
    "    \n",
    "    for partPublications in textPublications:\n",
    "        \n",
    "        \n",
    "        dateFound=newGetDate(partPublications)\n",
    "        if dateFound:\n",
    "            \n",
    "            \n",
    "            if not flag:\n",
    "                flag=True\n",
    "                tempPublications['year']=dateFound\n",
    "                publicationsIndex001=partPublications.find(dateFound)\n",
    "            \n",
    "                partPublications=partPublications[:publicationsIndex001]+partPublications[publicationsIndex001+len(dateFound):]\n",
    "                partPublications=removePrefix(partPublications)\n",
    "                detailsPublications+=\" \"+partPublications\n",
    "                \n",
    "                organizationPublications=findInstitute(partPublications)\n",
    "        \n",
    "                if organizationPublications:\n",
    "                \n",
    "                    organizationIndex001=partPublications.find(organizationPublications[0])\n",
    "            \n",
    "                    partPublications=partPublications[:organizationIndex001]+partPublications[organizationIndex001+len(organizationPublications[0]):]\n",
    "                    partPublications=removePrefix(partPublications)\n",
    "                #print(\"organizations : \",organizationPublications)\n",
    "                \n",
    "                    tempPublications['organization']=organizationPublications[0]\n",
    "                \n",
    "                continue\n",
    "            else:\n",
    "                tempPublications['publication details']=detailsPublications\n",
    "                detailsPublications=\"\"\n",
    "                allPublications.append(tempPublications)\n",
    "                \n",
    "                tempPublications=dict()\n",
    "                tempPublications['year']=dateFound\n",
    "                \n",
    "                publicationsIndex001=partPublications.find(dateFound)\n",
    "            \n",
    "                partPublications=partPublications[:publicationsIndex001]+partPublications[publicationsIndex001+len(dateFound):]\n",
    "                partPublications=removePrefix(partPublications)\n",
    "                \n",
    "                organizationPublications=findInstitute(partPublications)\n",
    "        \n",
    "                if organizationPublications:\n",
    "                \n",
    "                    organizationIndex001=partPublications.find(organizationPublications[0])\n",
    "            \n",
    "                    partPublications=partPublications[:organizationIndex001]+partPublications[organizationIndex001+len(organizationPublications[0]):]\n",
    "                    partPublications=removePrefix(partPublications)\n",
    "                #print(\"organizations : \",organizationPublications)\n",
    "                \n",
    "                    tempPublications['organization']=organizationPublications[0]\n",
    "                \n",
    "                \n",
    "                detailsPublications+=\" \"+partPublications\n",
    "        else:\n",
    "            partPublications=removePrefix(partPublications)\n",
    "            \n",
    "            organizationPublications=findInstitute(partPublications)\n",
    "        \n",
    "            if organizationPublications:\n",
    "                \n",
    "                organizationIndex001=partPublications.find(organizationPublications[0])\n",
    "            \n",
    "                partPublications=partPublications[:organizationIndex001]+partPublications[organizationIndex001+len(organizationPublications[0]):]\n",
    "                partPublications=removePrefix(partPublications)\n",
    "                #print(\"organizations : \",organizationPublications)\n",
    "                \n",
    "                tempPublications['organization']=organizationPublications[0]\n",
    "            \n",
    "            detailsPublications+=\" \"+partPublications\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # extracting name gives a lot of false result, \n",
    "        #as it contains name of things other than person name\n",
    "        \n",
    "        #namePublications=extract_name(partPublications)\n",
    "        #if namePublications:\n",
    "            #print(namePublications,type(namePublications))\n",
    "    \n",
    "        \n",
    "        \n",
    "    if tempPublications:\n",
    "        tempPublications['publication details']=detailsPublications\n",
    "        allPublications.append(tempPublications)\n",
    "            #print(dateFound,type(dateFound))\n",
    "        #print(partPublications)\n",
    "    return allPublications\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8adda400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:05.087082Z",
     "iopub.status.busy": "2022-09-06T10:36:05.086643Z",
     "iopub.status.idle": "2022-09-06T10:36:05.108179Z",
     "shell.execute_reply": "2022-09-06T10:36:05.106523Z"
    },
    "papermill": {
     "duration": 0.034984,
     "end_time": "2022-09-06T10:36:05.110825",
     "exception": false,
     "start_time": "2022-09-06T10:36:05.075841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "def handleRestPart(experiencePart):\n",
    "    allExperience=[]\n",
    "    detailsExperience=\"\"\n",
    "    tempExperience=dict()\n",
    "    flag=False # need for different in the 1st\n",
    "    for partExperience in experiencePart:\n",
    "        dateFound=newGetDate(partExperience)\n",
    "        if dateFound:\n",
    "            \n",
    "            \n",
    "            if not flag:\n",
    "                flag=True\n",
    "                tempExperience['year']=dateFound\n",
    "                partExperienceIndex001=partExperience.find(dateFound)\n",
    "            \n",
    "                partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(dateFound):]\n",
    "                partExperience=removePrefix(partExperience)\n",
    "                detailsExperience+=\" \"+partExperience\n",
    "                \n",
    "                organizationExperience=findInstitute(partExperience)\n",
    "        \n",
    "                if organizationExperience:\n",
    "                \n",
    "                    partExperienceIndex001=partExperience.find(organizationExperience[0])\n",
    "            \n",
    "                    partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(organizationExperience[0]):]\n",
    "                    partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                    tempExperience['organization']=organizationExperience[0]\n",
    "                \n",
    "                dsignationExperience=extractDsignation(partExperience)\n",
    "                if dsignationExperience:\n",
    "                \n",
    "                    partExperienceIndex001=partExperience.find(dsignationExperience[0])\n",
    "            \n",
    "                    partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(dsignationExperience[0]):]\n",
    "                    partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                    tempExperience['dsignation']=dsignationExperience[0]\n",
    "                \n",
    "                continue\n",
    "            else:\n",
    "                tempExperience['details']=detailsExperience\n",
    "                detailsExperience=\"\"\n",
    "                allExperience.append(tempExperience)\n",
    "                \n",
    "                tempExperience=dict()\n",
    "                tempExperience['year']=dateFound\n",
    "                \n",
    "                partExperienceIndex001=partExperience.find(dateFound)\n",
    "            \n",
    "                partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(dateFound):]\n",
    "                partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                organizationPublications=findInstitute(partExperience)\n",
    "        \n",
    "                if organizationPublications:\n",
    "                \n",
    "                    partExperienceIndex001=partExperience.find(organizationPublications[0])\n",
    "            \n",
    "                    partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(organizationPublications[0]):]\n",
    "                    partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                    tempExperience['organization']=organizationPublications[0]\n",
    "                dsignationExperience=extractDsignation(partExperience)\n",
    "                if dsignationExperience:\n",
    "                \n",
    "                    partExperienceIndex001=partExperience.find(dsignationExperience[0])\n",
    "            \n",
    "                    partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(dsignationExperience[0]):]\n",
    "                    partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                    tempExperience['dsignation']=dsignationExperience[0]\n",
    "                \n",
    "                detailsExperience+=\" \"+partExperience\n",
    "        else:\n",
    "            partExperience=removePrefix(partExperience)\n",
    "            \n",
    "            organizationPublications=findInstitute(partExperience)\n",
    "        \n",
    "            if organizationPublications:\n",
    "                \n",
    "                partExperienceIndex001=partExperience.find(organizationPublications[0])\n",
    "            \n",
    "                partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(organizationPublications[0]):]\n",
    "                partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                tempExperience['organization']=organizationPublications[0]\n",
    "            \n",
    "            \n",
    "            dsignationExperience=extractDsignation(partExperience)\n",
    "            if dsignationExperience:\n",
    "                \n",
    "                partExperienceIndex001=partExperience.find(dsignationExperience[0])\n",
    "            \n",
    "                partExperience=partExperience[:partExperienceIndex001]+partExperience[partExperienceIndex001+len(dsignationExperience[0]):]\n",
    "                partExperience=removePrefix(partExperience)\n",
    "                \n",
    "                tempExperience['dsignation']=dsignationExperience[0]\n",
    "            \n",
    "            detailsExperience+=\" \"+partExperience\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # extracting name gives a lot of false result, \n",
    "        #as it contains name of things other than person name\n",
    "        \n",
    "        #namepartExperience=extract_name(partExperience)\n",
    "        #if namepartExperience:\n",
    "            #print(namepartExperience,type(namepartExperience))\n",
    "    \n",
    "        \n",
    "        \n",
    "    if tempExperience:\n",
    "        tempExperience['details']=detailsExperience\n",
    "        allExperience.append(tempExperience)\n",
    "            \n",
    "    return allExperience\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21a9c9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:36:05.131868Z",
     "iopub.status.busy": "2022-09-06T10:36:05.130542Z",
     "iopub.status.idle": "2022-09-06T10:37:37.561410Z",
     "shell.execute_reply": "2022-09-06T10:37:37.560069Z"
    },
    "papermill": {
     "duration": 92.452984,
     "end_time": "2022-09-06T10:37:37.572867",
     "exception": false,
     "start_time": "2022-09-06T10:36:05.119883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "#import pdfplumber\n",
    "#import pandas as pd\n",
    "#import os\n",
    "# Importing required modules\n",
    "import PyPDF2\n",
    "\n",
    "def extract_pdf(pdf_path):\n",
    "    linesOfFile = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for pdf_page in pdf.pages:\n",
    "            single_page_text = pdf_page.extract_text()\n",
    "            for line in single_page_text.split('\\n'):\n",
    "                linesOfFile.append(line)\n",
    "                #print(linesOfFile)\n",
    "    return linesOfFile\n",
    "\n",
    "\n",
    "folder_with_pdfs = '../input/cvalltogether'\n",
    "linesOfFiles = []\n",
    "\n",
    "\n",
    "\n",
    "listOfPdfFiles=[]\n",
    "\n",
    "for pdf_file in os.listdir(folder_with_pdfs):\n",
    "    if pdf_file.endswith('.pdf'):\n",
    "        \n",
    "        #print(pdf_file)\n",
    "        listOfPdfFiles.append(pdf_file)\n",
    "        pdf_file_path = os.path.join(folder_with_pdfs, pdf_file)\n",
    "        \n",
    "        pdfFileObj = open(pdf_file_path,'rb')\n",
    "        \n",
    "        #print(pdfFileObj)\n",
    "        \n",
    "        pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "\n",
    "# Getting number of pages in pdf file\n",
    "        pages = pdfReader.numPages\n",
    "\n",
    "        totalText=[]\n",
    "\n",
    "# Loop for reading all the Pages\n",
    "        for i in range(pages):\n",
    "\n",
    "        # Creating a page object\n",
    "            pageObj = pdfReader.getPage(i)\n",
    "\n",
    "        # Printing Page Number\n",
    "        #print(\"Page No: \",i)\n",
    "\n",
    "        # Extracting text from page\n",
    "        # And splitting it into chunks of lines\n",
    "            text = pageObj.extractText().split(\"\\n\")\n",
    "        \n",
    "            totalText+=text\n",
    "        \n",
    "        \n",
    "# closing the pdf file object\n",
    "        pdfFileObj.close()\n",
    "        #print(totalText)\n",
    "        \n",
    "        sectionDictionary=dfPartByPart(totalText)\n",
    "        newSectionDictionary=reDistribute(sectionDictionary)\n",
    "        \n",
    "        tempData00=[]\n",
    "        \n",
    "        contactPart001,educationsPart001=dict(),dict()\n",
    "    \n",
    "        text00=newSectionDictionary['contacts / introductions']\n",
    "        personName00=extract_name(\",\".join(text00))\n",
    "    \n",
    "    \n",
    "        if len(personName00)==0:\n",
    "        \n",
    "            personNameLast=totalText[0]\n",
    "        else:\n",
    "            personNameLast=personName00[0]\n",
    "        #print(i,personNameLast)\n",
    "\n",
    "        \n",
    "        \n",
    "        for partSections in newSectionDictionary:\n",
    "            tempData00=[personNameLast]\n",
    "            if partSections=='contacts / introductions' and newSectionDictionary[partSections]:\n",
    "                tempData00.append(\"contact details\")\n",
    "                tempData00.append(partSections)\n",
    "                contactPart001=handleContacts(newSectionDictionary[partSections])\n",
    "                for parts in contactPart001:\n",
    "                    tempData00.append(parts)\n",
    "                    tempData00.append(contactPart001[parts])\n",
    "                \n",
    "                #print(tempData00)\n",
    "                    if len(tempData00)>1:\n",
    "                        allCVData.append(tempData00)\n",
    "                \n",
    "                    tempData00.pop()\n",
    "                    tempData00.pop()\n",
    "            \n",
    "                tempData00.pop()\n",
    "                tempData00.pop()\n",
    "            \n",
    "            #print(contactPart001) \n",
    "            #done for now\n",
    "            elif partSections=='educations / certificates / certifications' and newSectionDictionary[partSections]:\n",
    "                tempData00.append(\"qualifications details\")\n",
    "                tempData00.append(partSections)\n",
    "                educationsPart001=handleEducations(newSectionDictionary[partSections])\n",
    "                for parts001 in educationsPart001:\n",
    "                    tempData00.append(\"degree earned\")\n",
    "                    if 'degree' in parts001:\n",
    "                        tempData00.append(parts001['degree'])\n",
    "                    else:\n",
    "                        tempData00.append(\"Degree\")\n",
    "                \n",
    "                    for smallparts002 in parts001:\n",
    "                        tempData00.append(smallparts002)\n",
    "                        tempData00.append(parts001[smallparts002])\n",
    "                    \n",
    "                    #print(tempData00)\n",
    "                        if len(tempData00)>1:\n",
    "                            allCVData.append(tempData00.copy())\n",
    "                    \n",
    "                        tempData00.pop()\n",
    "                        tempData00.pop()\n",
    "                    tempData00.pop()\n",
    "                    tempData00.pop()\n",
    "                tempData00.pop()\n",
    "                tempData00.pop()\n",
    "            else:\n",
    "                tempEdge=partSections +\" experience\"\n",
    "        \n",
    "                tempData00.append(tempEdge)\n",
    "                tempData00.append(partSections)\n",
    "                restPart001=handleRestPart(newSectionDictionary[partSections])\n",
    "        \n",
    "                count=1\n",
    "                for parts001 in restPart001:\n",
    "                    newTempEdge=partSections +\" details\"\n",
    "                    tempData00.append(newTempEdge)\n",
    "                    tempData00.append(partSections+\" no.\"+str(count))\n",
    "            \n",
    "            \n",
    "                \n",
    "                    for smallparts002 in parts001:\n",
    "                        tempData00.append(smallparts002)\n",
    "                        tempData00.append(parts001[smallparts002])\n",
    "                    \n",
    "                    #print(tempData00)\n",
    "                        if len(tempData00)>1:\n",
    "                            allCVData.append(tempData00.copy())\n",
    "                    \n",
    "                        tempData00.pop()\n",
    "                        tempData00.pop()\n",
    "                    tempData00.pop()\n",
    "                    tempData00.pop()\n",
    "                    count+=1\n",
    "                tempData00.pop()\n",
    "                tempData00.pop()\n",
    "#print(\"complete\")\n",
    "        #break\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#df = pd.DataFrame(linesOfFiles)\n",
    "#df.to_csv('test.csv')\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc40ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:37:37.591760Z",
     "iopub.status.busy": "2022-09-06T10:37:37.591354Z",
     "iopub.status.idle": "2022-09-06T10:37:37.600548Z",
     "shell.execute_reply": "2022-09-06T10:37:37.599187Z"
    },
    "papermill": {
     "duration": 0.021908,
     "end_time": "2022-09-06T10:37:37.603364",
     "exception": false,
     "start_time": "2022-09-06T10:37:37.581456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'Ph.D.', 'degree', 'Ph.D.'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'Ph.D.', 'date', '1995'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'Ph.D.', 'organization', 'York University'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'Ph.D.', 'total details', 'EducationCourant Institute, New , New York, NY.'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'B.S.', 'degree', 'B.S.'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'B.S.', 'date', '1986'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'B.S.', 'organization', 'Stanford University'], ['Sunder Sethuraman', 'qualifications details', 'educations / certificates / certifications', 'degree earned', 'B.S.', 'total details', 'Stanford, CA.Diploma Florida High School, Tallahassee, FL.'], ['Sunder Sethuraman', 'appointments / experiences / services / employments / practices / professionals experience', 'appointments / experiences / services / employments / practices / professionals', 'appointments / experiences / services / employments / practices / professionals details', 'appointments / experiences / services / employments / practices / professionals no.1', 'year', '2011'], ['Sunder Sethuraman', 'appointments / experiences / services / employments / practices / professionals experience', 'appointments / experiences / services / employments / practices / professionals', 'appointments / experiences / services / employments / practices / professionals details', 'appointments / experiences / services / employments / practices / professionals no.1', 'dsignation', 'Professor']]\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "totalAllCVData=[]\n",
    "for check in allCVData:\n",
    "    if len(check)>1:\n",
    "        totalAllCVData.append(check)\n",
    "print(totalAllCVData[:10])\n",
    "\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fa694d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-06T10:37:37.623349Z",
     "iopub.status.busy": "2022-09-06T10:37:37.622912Z",
     "iopub.status.idle": "2022-09-06T10:37:37.692438Z",
     "shell.execute_reply": "2022-09-06T10:37:37.690882Z"
    },
    "papermill": {
     "duration": 0.082587,
     "end_time": "2022-09-06T10:37:37.695213",
     "exception": false,
     "start_time": "2022-09-06T10:37:37.612626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#write.csv(allCVData, \"mycsv.csv\")\n",
    "\n",
    "#header = ['head','relation','tail']\n",
    "\n",
    "with open('CVpdftotalAllCVData001.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header , already has a header\n",
    "    #writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(totalAllCVData)\n",
    "\n",
    "print(\"complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 146.283885,
   "end_time": "2022-09-06T10:37:40.449095",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-06T10:35:14.165210",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
